{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e272308-d79d-4eb9-b5e8-71808fc1bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data preparation\n",
    "df = pd.read_csv('course_lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27b3b5f-f09f-4d8a-a64b-b5bc960b9461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0176c4-4e56-4bff-be88-c33df3f35019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "dtype: int64\n",
      "lead_source          128\n",
      "industry             134\n",
      "employment_status    100\n",
      "location              63\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "numerical_column = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "categorical_column = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "\n",
    "# cek missing value\n",
    "print(df[numerical_column].isnull().sum())\n",
    "print(df[categorical_column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740be57e-90bf-4d0e-bc40-7a943b1812d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create fill dictionary based on column types\n",
    "fill_dict = {}\n",
    "\n",
    "# for numerical columns  \n",
    "for col in numerical_column:\n",
    "    fill_dict[col] = 0.0\n",
    "\n",
    "# for categorical columns\n",
    "for col in categorical_column:\n",
    "    fill_dict[col] = 'NA'\n",
    "\n",
    "# fill all at once\n",
    "df = df.fillna(fill_dict)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc9e713-2a22-46a7-ad65-95f4eb24b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    retail\n",
      "Name: industry, dtype: object\n",
      "industry\n",
      "retail           203\n",
      "finance          200\n",
      "other            198\n",
      "healthcare       187\n",
      "education        187\n",
      "technology       179\n",
      "manufacturing    174\n",
      "NA               134\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. industry mode\n",
    "print(df.industry.mode())\n",
    "print(df.industry.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad1b15e-5ac2-46f8-8e00-44210bea452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_courses_viewed    0.435914\n",
       "interaction_count           0.374573\n",
       "lead_score                  0.193673\n",
       "annual_income               0.053131\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. correlation\n",
    "df[numerical_column].corrwith(df.converted).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd7fb9ba-012d-44e3-858d-7ea4d71b8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for validation framework\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# need to split data to 60 train 20 val and 20 test\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values\n",
    "\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd73a8cc-ef9c-43de-ab9a-120e5d3c3c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.04\n",
       "industry             0.01\n",
       "employment_status    0.01\n",
       "location             0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. mutual information\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def mutual_info_converted_score(feature):\n",
    "    return round(mutual_info_score(feature, y_train),2)\n",
    "\n",
    "df_train[categorical_column].apply(mutual_info_converted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc5f4eb-2161-4572-9fed-410ce9949dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to one hot encoding\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# train data set. convert categorical to one hot encoding\n",
    "train_dicts_categorical = df_train[categorical_column].to_dict(orient=\"records\")\n",
    "X_train_one_hot = dv.fit_transform(train_dicts_categorical)\n",
    "\n",
    "# convert one-hot encoded features to DataFrame with proper column names\n",
    "X_train_categorical = pd.DataFrame(X_train_one_hot, columns=dv.get_feature_names_out())\n",
    "# get numerical feature\n",
    "X_train_numerical = df_train[numerical_column]\n",
    "\n",
    "# reset indices to ensure proper alignment\n",
    "X_train_numerical = X_train_numerical.reset_index(drop=True)\n",
    "X_train_categorical = X_train_categorical.reset_index(drop=True)\n",
    "\n",
    "# combine horizontally categorical feature that already convert with one hot encode + numerical feature\n",
    "X_train = pd.concat([X_train_numerical, X_train_categorical], axis=1)\n",
    "\n",
    "# val data set. convert categorical to one hot encoding\n",
    "val_dicts_categorical = df_val[categorical_column].to_dict(orient=\"records\")\n",
    "X_val_one_hot = dv.fit_transform(val_dicts_categorical)\n",
    "\n",
    "# convert one-hot encoded features to DataFrame with proper column names\n",
    "X_val_categorical = pd.DataFrame(X_val_one_hot, columns=dv.get_feature_names_out())\n",
    "# get numerical feature\n",
    "X_val_numerical = df_val[numerical_column]\n",
    "\n",
    "# reset indices to ensure proper alignment\n",
    "X_val_numerical = X_val_numerical.reset_index(drop=True)\n",
    "X_val_categorical = X_val_categorical.reset_index(drop=True)\n",
    "\n",
    "# combine horizontally categorical feature that already convert with one hot encode + numerical feature\n",
    "X_val = pd.concat([X_val_numerical, X_val_categorical], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39bf8e73-2c1c-47b8-b68a-524c2173f3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6996587030716723\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict proba will produce two column\n",
    "# first column probability of 0, second column probability of 1\n",
    "# in this case 0 = not converted, 1 = converted\n",
    "y_val_pred = model.predict_proba(X_val)[:,1]\n",
    "converted_decision = (y_val_pred >= 0.5)\n",
    "\n",
    "# 4. count the accuracy\n",
    "accuracy = (y_val == converted_decision.astype('int')).mean()\n",
    "print(accuracy)\n",
    "print(round(accuracy, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618f5023-303a-407f-8f97-693c590cc695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: 0.6996587030716723\n",
      "Without 'industry': accuracy = 0.699659, difference = 0.000000\n",
      "Without 'employment_status': accuracy = 0.696246, difference = 0.003413\n",
      "Without 'lead_score': accuracy = 0.706485, difference = -0.006826\n",
      "\n",
      "The feature with the smallest difference is 'industry' with difference = 0.000000\n",
      "\n",
      "ANSWER: industry\n"
     ]
    }
   ],
   "source": [
    "# 5.\n",
    "# first, let's get the original accuracy with all features\n",
    "original_accuracy = (y_val == converted_decision.astype('int')).mean()\n",
    "print(f\"Original accuracy: {original_accuracy}\")\n",
    "\n",
    "# dictionary to store accuracy differences for the three features\n",
    "accuracy_differences = {}\n",
    "\n",
    "# features to test excluding\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "\n",
    "for feature_to_exclude in features_to_test:\n",
    "    # check if the feature exists in our dataset\n",
    "    if feature_to_exclude in X_train.columns:\n",
    "        # exclude the single feature\n",
    "        X_train_reduced = X_train.drop(columns=[feature_to_exclude])\n",
    "        X_val_reduced = X_val.drop(columns=[feature_to_exclude])\n",
    "    else:\n",
    "        # if it's a categorical feature that was one-hot encoded, find all related columns\n",
    "        related_columns = [col for col in X_train.columns if col.startswith(feature_to_exclude + '=')]\n",
    "        if related_columns:\n",
    "            # exclude all columns related to this categorical feature\n",
    "            X_train_reduced = X_train.drop(columns=related_columns)\n",
    "            X_val_reduced = X_val.drop(columns=related_columns)\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{feature_to_exclude}' not found in dataset\")\n",
    "            continue\n",
    "    \n",
    "    # train logistic regression with the same parameters\n",
    "    model_reduced = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_reduced.fit(X_train_reduced, y_train)\n",
    "    \n",
    "    # make predictions\n",
    "    y_val_pred_reduced = model_reduced.predict_proba(X_val_reduced)[:, 1]\n",
    "    converted_decision_reduced = (y_val_pred_reduced >= 0.5)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy_reduced = (y_val == converted_decision_reduced.astype('int')).mean()\n",
    "    \n",
    "    # calculate the difference from original accuracy\n",
    "    difference = original_accuracy - accuracy_reduced\n",
    "    accuracy_differences[feature_to_exclude] = difference\n",
    "    \n",
    "    print(f\"Without '{feature_to_exclude}': accuracy = {accuracy_reduced:.6f}, difference = {difference:.6f}\")\n",
    "\n",
    "# find which feature has the smallest absolute difference\n",
    "smallest_diff_feature = min(accuracy_differences.items(), key=lambda x: abs(x[1]))\n",
    "print(f\"\\nThe feature with the smallest difference is '{smallest_diff_feature[0]}' with difference = {smallest_diff_feature[1]:.6f}\")\n",
    "\n",
    "# print the answer\n",
    "print(f\"\\nANSWER: {smallest_diff_feature[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9963bc4-96ba-408c-823c-cb2a1fe381d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training regularized logistic regression with different C values:\n",
      "C\t\tAccuracy\n",
      "0.01\t\t0.6996587030716723\n",
      "0.1\t\t0.6996587030716723\n",
      "1\t\t0.6996587030716723\n",
      "10\t\t0.6996587030716723\n",
      "100\t\t0.6996587030716723\n",
      "\n",
      "Best C value: 0.01 with accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "# values of C to try\n",
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# dictionary to store accuracies for each C\n",
    "accuracies = {}\n",
    "\n",
    "print(\"Training regularized logistic regression with different C values:\")\n",
    "print(\"C\\t\\tAccuracy\")\n",
    "\n",
    "for c in c_values:\n",
    "    # train logistic regression with current C value\n",
    "    model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    converted_decision = (y_val_pred >= 0.5)\n",
    "    \n",
    "    # calculate accuracy and round to 3 decimal digits\n",
    "    accuracy = (y_val == converted_decision.astype('int')).mean()\n",
    "    accuracy_rounded = round(accuracy, 3)\n",
    "    accuracies[c] = accuracy_rounded\n",
    "    \n",
    "    print(f\"{c}\\t\\t{accuracy}\")\n",
    "\n",
    "# find the C value that gives the best accuracy\n",
    "best_c = max(accuracies.items(), key=lambda x: x[1])\n",
    "print(f\"\\nBest C value: {best_c[0]} with accuracy: {best_c[1]}\")\n",
    "# import numpy as np\n",
    "# print(\"Debugging the model predictions:\")\n",
    "\n",
    "# for c in [0.01, 0.1, 1, 10, 100]:\n",
    "#     # Train model\n",
    "#     model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Get predictions and probabilities\n",
    "#     y_val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "#     y_val_pred = model.predict(X_val)\n",
    "    \n",
    "#     # Check if predictions are all the same class\n",
    "#     unique_predictions = np.unique(y_val_pred)\n",
    "#     proba_range = y_val_pred_proba.max() - y_val_pred_proba.min()\n",
    "    \n",
    "#     print(f\"\\nC = {c}:\")\n",
    "#     print(f\"  Unique predictions: {unique_predictions}\")\n",
    "#     print(f\"  Probability range: {proba_range:.6f}\")\n",
    "#     print(f\"  Mean probability: {y_val_pred_proba.mean():.6f}\")\n",
    "    \n",
    "#     # Calculate accuracy using different methods to verify\n",
    "#     accuracy1 = (y_val == y_val_pred).mean()\n",
    "#     accuracy2 = (y_val == (y_val_pred_proba >= 0.5).astype(int)).mean()\n",
    "#     print(f\"  Accuracy (predict): {accuracy1}\")\n",
    "#     print(f\"  Accuracy (proba>=0.5): {accuracy2}\")\n",
    "\n",
    "# # Let's also check the data characteristics\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"Data diagnostics:\")\n",
    "# print(f\"Training set shape: {X_train.shape}\")\n",
    "# print(f\"Validation set shape: {X_val.shape}\")\n",
    "# print(f\"y_train value counts:\\n{y_train.value_counts()}\")\n",
    "# print(f\"y_val value counts:\\n{y_val.value_counts()}\")\n",
    "\n",
    "# # Check for constant predictions\n",
    "# print(f\"\\nBaseline accuracy (predicting majority class): {max(y_val.value_counts(normalize=True))}\")\n",
    "\n",
    "# # Check if features are scaled properly (regularization is sensitive to scale)\n",
    "# print(f\"\\nFeature ranges (min, max):\")\n",
    "# for col in X_train.columns[:5]:  # Check first 5 features\n",
    "#     print(f\"  {col}: [{X_train[col].min():.3f}, {X_train[col].max():.3f}]\")\n",
    "\n",
    "# # Let's try with feature scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"Trying with feature scaling:\")\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# for c in [0.01, 0.1, 1, 10, 100]:\n",
    "#     model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "#     model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "#     y_val_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "#     converted_decision = (y_val_pred_proba >= 0.5)\n",
    "#     accuracy = (y_val == converted_decision.astype('int')).mean()\n",
    "    \n",
    "#     print(f\"C = {c}: accuracy = {accuracy:.6f}\")\n",
    "\n",
    "# # Let's also check the coefficients to see if regularization is working\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"Checking coefficients for different C values:\")\n",
    "\n",
    "# for c in [0.01, 0.1, 1, 10, 100]:\n",
    "#     model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     coef_sum = np.sum(np.abs(model.coef_))\n",
    "#     print(f\"C = {c}: sum of absolute coefficients = {coef_sum:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577cc6a-f108-4947-882f-487a4e4b5d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
